
# [clase1-2021-01-28.mp4](https://github.com/BayesDeLasProvinciasUnidasDelSur/curso/releases/download/2021.1/clase1-2021-01-28.mp4)

Es importante haber revisado esta clase antes de empezar.
Cómputo de creencias honestas (o teoría de la probabilidad).
Monty Hall Bayesiano-Laplaciano resuelto dividiendo la certidumbre por los caminos del modelo causal.

# [clase_funciones-2021-04-08.mp4](https://github.com/BayesDeLasProvinciasUnidasDelSur/curso/releases/download/2021.1/clase_funciones-2021-04-08.mp4)

Datos como fuciones.
Estructura invariante del dato.
Examenes de la operacionalización del dato.
Modelos causales como funciones.
Modelo ELO.
Modelos no-lineales.
Atractores fijos, períodicos y caótico (sensibilidad a condiciones iniciales).
La maquina de Turing como sistema deteminista. ¿Podemos computar números aleatorios?.
Podemos "imitarlos", no generarlos. Pero existe el conceptos teórico de "libre albedrio", que las personas no son funciones, que no tienen destinos inevitable.
En estos casos usamos fuciones de probabilidad para expresar nuestra incertidumbre.
Fundamentos de validez del conocimiento ("afirmar sólo lo que se sabe"), criterio de honestidad como función.
Hipótesis indicadora de ELO.
El teorema de bayes como generalización de la hipótesis indicadora.
Los datos como síntesis de las evidencias formales y empíricas
Concepto de "base empírica" y t-teoricidad.

# [clase_bayes2-2021-06-30.mp4](https://github.com/BayesDeLasProvinciasUnidasDelSur/curso/releases/download/2021.1/clase_bayes2-2021-06-30.mp4)

Intro histórica (con Árabes)
Distribución Binomial y el coeficiente binomial.
Prop7 de Bayes: el ejemplo de la mesa de billar.
Distribución Beta para k y n naturales.
Visualizaciones.
Derivación de Beta como posterior con un prior uniforme.
Derivación de la constate de normalización con un prior uniforme. 
Implementación en vivo para calacular la constante de normalización con diferentes priors.
Resumen, Máximo, mediana, esperanza.
La esperanza de la Beta como una frecuencia que incluye dos eventos más, uno positivo y otro negativo.
El mismo resultado al que llega Laplace cuando calcula la esperanza de que mañana salga el sol dado que salió los últimos N grande de días. 
ABtest y visualización.


# [clase_sumproduct_1_2021-06-02.mp4](https://github.com/BayesDeLasProvinciasUnidasDelSur/curso/releases/download/2021.1/clase_sumproduct_1_2021-06-02.mp4)

Presentamos el modelo causal de la Alarma, Entradera, Terremoto. Hablamos en detalle de los priors (condicionales) . Caculamos la conjunta en un punto. La marginal de la Alarma. Hasta ahí quedó bien. Al final nos quedamos sin tiempo y quedó confuso

# [clase_sumproduct_2_2021-06-16.mp4](https://github.com/BayesDeLasProvinciasUnidasDelSur/curso/releases/download/2021.1/clase_sumproduct_2_2021-06-16.mp4)

Hablamos de la imagen del final que tiene al Inti, el sol de la bandera. Revisamos por arriba lo que vimos en la reunión pasada (Sum-product 1). Implementamos en Julia los priors como matrices, y las marginales como funciones. Presentamos el sum-product algorithm con detalle (la proxima va a haber que explicar mejor la notación). Y vimos ejemplos: calculamos todo los mensajes cuando no hay observables (y sus marginales). Y nos hicimos la pregunta que nos va a llevar a D-SEPARATION, respecto del cierre y la apertura de los flujos de inferencia y resolvimos parcialmente la pregunta pasando mensajes cuando hay observables.  

